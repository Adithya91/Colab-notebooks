{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2ohOONFe3y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pyopencl as cl\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "from pyopencl import array\n",
        "from time import time\n",
        "\n",
        "def matrix_log10(queue,ctx,prg,a_np,res_np):\n",
        " mf = cl.mem_flags\n",
        " t1 = time()\n",
        " inp = a_np \n",
        " a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
        " _knl = prg.matrix_log10\n",
        " _knl.set_scalar_arg_dtypes([None,np.uint32])\n",
        " _knl(queue,a_np.shape, None,a_g,a_np.shape[0])\n",
        " cl.enqueue_copy(queue,res_np, a_g)\n",
        " push_time = time()-t1\n",
        "\n",
        " print('matrix_log10\\n\\n')\n",
        " print('Input Matrix\\n')\n",
        " print(inp)\n",
        " print('\\n')\n",
        " print('GPU Matrix \\n')\n",
        " print(res_np)\n",
        " print('\\n')\n",
        " print('CPU Matrix \\n') \n",
        " t1 = time()\n",
        " res_p = np.log10(a_np)\n",
        " cpu_time = time()-t1\n",
        " print(res_p)\n",
        " print('\\n')\n",
        " if (push_time<cpu_time):\n",
        "  print('GPU execution is faster')\n",
        " else:\n",
        "  print('CPU execution is faster')\n",
        "\n",
        "def matrix_minus_scalar(queue,ctx,prg,a_np,res_np,scalar):\n",
        " mf = cl.mem_flags\n",
        " t1 = time()\n",
        " inp = a_np \n",
        " a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
        " _knl = prg.matrix_minus_scalar\n",
        " _knl.set_scalar_arg_dtypes([None,np.uint32,np.double])\n",
        " _knl(queue,a_np.shape, None,a_g,a_np.shape[0],scalar)\n",
        " cl.enqueue_copy(queue,res_np, a_g)\n",
        " push_time = time()-t1\n",
        "\n",
        " print('matrix_minus_scalar\\n\\n')\n",
        " print('Input Matrix\\n')\n",
        " print(inp)\n",
        " print('\\n')\n",
        " print('GPU Matrix \\n')\n",
        " print(res_np)\n",
        " print('\\n')\n",
        " print('CPU Matrix \\n') \n",
        " t1 = time()\n",
        " res_p = a_np-scalar\n",
        " cpu_time = time()-t1\n",
        " print(res_p)\n",
        " print('\\n')\n",
        " if (push_time<cpu_time):\n",
        "  print('GPU execution is faster')\n",
        " else:\n",
        "  print('CPU execution is faster')\n",
        "\n",
        "def matrix_minus_matrix(queue,ctx,prg,a_np,b_np,res_np):\n",
        " mf = cl.mem_flags\n",
        " t1 = time() \n",
        " a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
        " b_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b_np)\n",
        " res_g = cl.Buffer(ctx, mf.WRITE_ONLY, res_np.nbytes)\n",
        " _knl = prg.matrix_minus_matrix\n",
        " _knl.set_scalar_arg_dtypes([None,np.uint32,None,None])\n",
        " _knl(queue,res_np.shape, None,a_g,a_np.shape[0],b_g,res_g)\n",
        " cl.enqueue_copy(queue, res_np, res_g)\n",
        " push_time = time()-t1\n",
        " print('matrix_minus_matrix\\n\\n')\n",
        " print('Input Matrix\\n')\n",
        " print(a_np)\n",
        " print(b_np)\n",
        " print('\\n')\n",
        " print('GPU Matrix \\n')\n",
        " print(res_np)\n",
        " print('\\n')\n",
        " print('CPU Matrix \\n') \n",
        " t1 = time()\n",
        " res_p = a_np-b_np\n",
        " cpu_time = time()-t1\n",
        " print(res_p)\n",
        " \n",
        " print('\\n')\n",
        " if (push_time<cpu_time):\n",
        "  print('GPU execution is faster\\n')\n",
        " else:\n",
        "  print('CPU execution is faster\\n')\n",
        "\n",
        "def matrix_multiply_col_vector(queue,ctx,prg,a_np,vec,M):\n",
        " mf = cl.mem_flags\n",
        " res_np = np.zeros((M,1),np.float32)\n",
        " t1 = time() \n",
        " a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
        " vec_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=vec)\n",
        " res_g = cl.Buffer(ctx, mf.WRITE_ONLY, res_np.nbytes)\n",
        " _knl = prg.vector_mul\n",
        " _knl(queue,res_np.shape, None,a_g,vec_g,res_g)\n",
        " cl.enqueue_copy(queue, res_np, res_g)\n",
        " push_time = time()-t1\n",
        " print('matrix_multiply_col_vector\\n\\n')\n",
        " print('Input Matrix\\n')\n",
        " print(a_np)\n",
        " print(vec)\n",
        " print('\\n')\n",
        " print('GPU Matrix \\n')\n",
        " print(res_np)\n",
        " print('\\n')\n",
        " print('CPU Matrix \\n') \n",
        " t1 = time()\n",
        " res_p = np.dot(a_np,vec)\n",
        " cpu_time = time()-t1\n",
        " print(res_p)\n",
        " \n",
        " print('\\n')\n",
        " if (push_time<cpu_time):\n",
        "  print('GPU execution is faster\\n')\n",
        " else:\n",
        "  print('CPU execution is faster\\n')\n",
        "\n",
        "def matrix_divide_matrix(queue,ctx,prg,a_np,b_np,res_np):\n",
        " mf = cl.mem_flags\n",
        " t1 = time() \n",
        " a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
        " b_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b_np)\n",
        " res_g = cl.Buffer(ctx, mf.WRITE_ONLY, res_np.nbytes)\n",
        " _knl = prg.matrix_minus_matrix\n",
        " _knl.set_scalar_arg_dtypes([None,np.uint32,None,None])\n",
        " _knl(queue,res_np.shape, None,a_g,a_np.shape[0],b_g,res_g)\n",
        " cl.enqueue_copy(queue, res_np, res_g)\n",
        " push_time = time()-t1\n",
        " print('matrix_divide_matrix\\n\\n')\n",
        " print('Input Matrix\\n')\n",
        " print(a_np)\n",
        " print(b_np)\n",
        " print('\\n')\n",
        " print('GPU Matrix \\n')\n",
        " print(res_np)\n",
        " print('\\n')\n",
        " print('CPU Matrix \\n') \n",
        " t1 = time()\n",
        " res_p = a_np/b_np\n",
        " cpu_time = time()-t1\n",
        " print(res_p)\n",
        " \n",
        " print('\\n')\n",
        " if (push_time<cpu_time):\n",
        "  print('GPU execution is faster\\n')\n",
        " else:\n",
        "  print('CPU execution is faster\\n')\n",
        "\n",
        "def matrix_transpose(queue,ctx,prg,a_np,res_np):\n",
        " mf = cl.mem_flags\n",
        " BLOCK_DIM = 16\n",
        " t1 = time() \n",
        " a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
        " res_g = cl.Buffer(ctx, mf.WRITE_ONLY, res_np.nbytes)\n",
        " _knl = prg.matrix_transpose\n",
        " _knl.set_scalar_arg_dtypes([None,None,np.uint32,np.uint32,None])\n",
        " _knl(queue,res_np.shape,None,a_g,res_g,a_np.shape[1],a_np.shape[0],cl.LocalMemory(4*BLOCK_DIM*(BLOCK_DIM+1)))\n",
        " cl.enqueue_copy(queue, res_np, res_g)\n",
        " push_time = time()-t1\n",
        " print('matrix_divide_matrix\\n\\n')\n",
        " print('Input Matrix\\n')\n",
        " print(a_np)\n",
        " print('\\n')\n",
        " print('GPU Matrix \\n')\n",
        " print(res_np)\n",
        " print('\\n')\n",
        " print('CPU Matrix \\n') \n",
        " t1 = time()\n",
        " tran = [[a_np[j][i] for j in range(len(a_np))] for i in range(len(a_np[0]))] \n",
        " cpu_time = time() - t1\n",
        " print(\"\\n\") \n",
        " \n",
        " for item in tran: \n",
        "    print(item)\n",
        " \n",
        " print('\\n')\n",
        " if (push_time<cpu_time):\n",
        "  print('GPU execution is faster')\n",
        " else:\n",
        "  print('CPU execution is faster')\n",
        "\n",
        "def main():\n",
        " N = 9999\n",
        " M = 9999\n",
        " a_np = np.random.rand(M,N).astype(np.float64)\n",
        " b_np = np.random.rand(M,N).astype(np.float64)\n",
        " res_np = np.zeros((M,N),np.float64)\n",
        " mat_np = np.random.rand(M,N).astype(np.float32)\n",
        " vec = np.random.rand(N,1).astype(np.float32)\n",
        " scalar = 2\n",
        " ctx = cl.create_some_context()\n",
        " queue = cl.CommandQueue(ctx)\n",
        " prg = cl.Program(ctx, \"\"\"\n",
        "\t __kernel void matrix_log10\n",
        "\t\t(\n",
        "\t\t\t__global double * matrix,\t\n",
        "\t\t\tuint row_size\t\t\t\n",
        "\t\t)\n",
        "\t{\n",
        "\t\t// gid0 - numer wiersza macierzy input\n",
        "\t\tuint gid0 = get_global_id(0);\n",
        "\t\t// gid1 - numer elementu w wierszu.\n",
        "\t\tuint gid1 = get_global_id(1);\n",
        "\n",
        "\t\tif(gid1 >= row_size)\n",
        "\t\t{\n",
        "\t\t\treturn;\n",
        "\t\t}\n",
        "\t\n",
        "\t\tuint idx = gid0 * row_size + gid1;\n",
        "\n",
        "\t\tdouble m = matrix[idx];\n",
        "\t\tm = log10(m);\n",
        "\t\tmatrix[idx] = m;\n",
        "\t}\n",
        "\n",
        "\t__kernel void matrix_minus_scalar\n",
        "\t\t(\n",
        "\t\t\t__global double * matrix,\t\n",
        "\t\t\tuint row_size,\t\t\t\n",
        "\t\t\tdouble subtrahend\t\t\n",
        "\t\t)\n",
        "\t{\n",
        "\t\t// gid0 - numer wiersza macierzy input\n",
        "\t\tuint gid0 = get_global_id(0);\n",
        "\t\t// gid1 - numer elementu w wierszu.\n",
        "\t\tuint gid1 = get_global_id(1);\n",
        "\n",
        "\t\tif(gid1 >= row_size)\n",
        "\t\t{\n",
        "\t\t\treturn;\n",
        "\t\t}\n",
        "\t\n",
        "\t\tuint idx = gid0 * row_size + gid1;\n",
        "\n",
        "\t\tdouble m = matrix[idx];\n",
        "\t\tm -= subtrahend;\n",
        "\t\tmatrix[idx] = m;\n",
        "\t}\n",
        "\n",
        "\t__kernel void matrix_minus_matrix\n",
        "\t\t(\n",
        "\t\t\t__global double * matrix,\t\n",
        "\t\t\tuint row_size,\t\t\t\n",
        "\t\t\t__global double * subtrahend_matrix,\t\t\n",
        "\t\t\t__global double * output_matrix\t\n",
        "\t\t)\n",
        "\t{\n",
        "\t\t// gid0 - numer wiersza macierzy input\n",
        "\t\tuint gid0 = get_global_id(0);\n",
        "\t\t// gid1 - numer elementu w wierszu.\n",
        "\t\tuint gid1 = get_global_id(1);\n",
        "\n",
        "\t\tif(gid1 >= row_size)\n",
        "\t\t{\n",
        "\t\t\treturn;\n",
        "\t\t}\n",
        "\t\n",
        "\t\tuint idx = gid0 * row_size + gid1;\n",
        "\n",
        "\t\tdouble value = matrix[idx];\n",
        "\t\tdouble subtrahend = subtrahend_matrix[idx];\n",
        "\n",
        "\t\tvalue -= subtrahend;\n",
        "\n",
        "\t\toutput_matrix[idx] = value;\n",
        "\t}\n",
        "\n",
        "\t__kernel void matrix_divide_matrix\n",
        "\t\t(\n",
        "\t\t\t__global double * dividend_matrix,\t\n",
        "\t\t\tuint row_size,\t\t\t\t\n",
        "\t\t\t__global double * divisor_matrix,\t\n",
        "\t\t\t__global double * output_matrix\t\t\n",
        "\t\t)\n",
        "\t{\n",
        "\t\t// gid0 - numer wiersza macierzy input\n",
        "\t\tuint gid0 = get_global_id(0);\n",
        "\t\t// gid1 - numer elementu w wierszu.\n",
        "\t\tuint gid1 = get_global_id(1);\n",
        "\n",
        "\t\tif(gid1 >= row_size)\n",
        "\t\t{\n",
        "\t\t\treturn;\n",
        "\t\t}\n",
        "\t\n",
        "\t\tuint idx = gid0 * row_size + gid1;\n",
        "\n",
        "\t\tdouble dividend = dividend_matrix[idx];\n",
        "\t\tdouble divisor = divisor_matrix[idx];\n",
        "\n",
        "\t\toutput_matrix[idx] = dividend /= divisor;\n",
        "\t}\n",
        "\n",
        "\t// Mnoży każdy element z i-tej kolumny przez i-ty element\n",
        "\t// podanego wektora.\n",
        "\t//\n",
        "\t__kernel void matrix_multiply_col_vector\n",
        "\t\t(\n",
        "\t\t\t__global double * matrix,\t\n",
        "\t\t\tuint row_size,\t\t\t\n",
        "\t\t\t__constant double * vector,\t\n",
        "\t\t\t\t\t\t\t\n",
        "\t\t\t__global double * output_matrix\t\n",
        "\t\t)\n",
        "\t{\n",
        "\t\t// gid0 - numer wiersza macierzy input\n",
        "\t\tuint gid0 = get_global_id(0);\n",
        "\t\t// gid1 - numer elementu w wierszu (numer kolumny).\n",
        "\t\tuint gid1 = get_global_id(1);\n",
        "\n",
        "\t\tif(gid1 >= row_size)\n",
        "\t\t{\n",
        "\t\t\treturn;\n",
        "\t\t}\n",
        "\t\n",
        "\t\tuint idx = gid0 * row_size + gid1;\n",
        "\t\tuint col_idx = gid1;\n",
        "\n",
        "\t\tdouble value = matrix[idx];\n",
        "\t\tdouble m = vector[col_idx];\n",
        "\n",
        "\t\tvalue *= m;\n",
        "\n",
        "\t\toutput_matrix[idx] = value;\n",
        "\t}\n",
        "\n",
        "\t__kernel void vector_mul(\n",
        "\t    __global const float4 *a_g, __global const float4 *b_g, __global float *res_g)\n",
        "\t{\n",
        "\t  int gid = get_global_id(0);\n",
        "\t  res_g[gid] = dot(a_g[gid], b_g[0]);\n",
        "\t}\n",
        "\n",
        "\t#define M_TRANSPOSE_BLOCK_DIM 16\n",
        "\n",
        "\t__kernel void matrix_transpose\n",
        "\t\t(\n",
        "\t\t\t__global double * matrix,\t\n",
        "\t\t\t__global double * tmatrix,\t\n",
        "\t\t\tuint width,\t\t\t\n",
        "\t\t\tuint height,\t\t\t\n",
        "\t\t\t__local double * scratch\n",
        "\t\t)\n",
        "\t{\n",
        "\t\t// gid0 - numer wiersza\n",
        "\t\tuint x_idx = get_global_id(0);\n",
        "\t\t// gid1 - numer kolumny\n",
        "\t\tuint y_idx = get_global_id(1);\n",
        "\t\n",
        "\t\tuint idx;\n",
        "\n",
        "\t\t// Pobieranie wartości z matrix\t\n",
        "\t\tif((x_idx < width) && (y_idx < height))\n",
        "\t\t{\t\n",
        "\t\t\tidx = y_idx * width + x_idx;\n",
        "\t\t\tscratch[get_local_id(1)*(M_TRANSPOSE_BLOCK_DIM+1)+get_local_id(0)] = matrix[idx];\n",
        "\t\t}\n",
        "\t\tbarrier(CLK_LOCAL_MEM_FENCE);\n",
        "\n",
        "\n",
        "\t\t// Pobieranie wartości z matrix\t\n",
        "\t\tx_idx = get_group_id(1) * M_TRANSPOSE_BLOCK_DIM + get_local_id(0);\n",
        "\t\ty_idx = get_group_id(0) * M_TRANSPOSE_BLOCK_DIM + get_local_id(1);\n",
        "\t\tif((x_idx < height) && (y_idx < width))\n",
        "\t\t{\t\n",
        "\t\t\tidx = y_idx * height + x_idx;\n",
        "\t\t\ttmatrix[idx] = scratch[get_local_id(0)*(M_TRANSPOSE_BLOCK_DIM+1)+get_local_id(1)];\n",
        "\t\t}\n",
        "\t}\"\"\").build()\n",
        " if(0):\n",
        "  matrix_log10(queue,ctx,prg,a_np,res_np)\n",
        " if(0):\n",
        "  matrix_minus_matrix(queue,ctx,prg,a_np,b_np,res_np)\n",
        " if(1):\n",
        "  matrix_minus_scalar(queue,ctx,prg,a_np,res_np,scalar)\n",
        " if(0):\n",
        "  matrix_multiply_col_vector(queue,ctx,prg,mat_np,vec,M)\n",
        " if(0):\n",
        "  matrix_divide_matrix(queue,ctx,prg,a_np,b_np,res_np)\n",
        " if(0):\n",
        "  matrix_transpose(queue,ctx,prg,a_np,res_np)\n",
        " \n",
        "if __name__ == '__main__':\n",
        " main()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
